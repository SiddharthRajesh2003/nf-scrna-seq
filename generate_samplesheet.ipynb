{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d4a5c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('metadata/OSA_SraRunTable.csv', header = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a44fd62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sample_names(samples_df, naming_scheme='sequential'):\n",
    "    \"\"\"\n",
    "    Generate sample names based on the chosen naming scheme\n",
    "    \n",
    "    Args:\n",
    "        samples_df: DataFrame with grouped samples\n",
    "        naming_scheme: 'gsm', 'status', or 'sequential'\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary mapping GSM IDs to sample names\n",
    "    \"\"\"\n",
    "    sample_mapping = {}\n",
    "    \n",
    "    if naming_scheme == 'gsm':\n",
    "        for _, row in samples_df.iterrows():\n",
    "            sample_mapping[row['Sample Name']] = row['Sample Name']\n",
    "    \n",
    "    elif naming_scheme == 'status':\n",
    "        for _, row in samples_df.iterrows():\n",
    "            gsm = row['Sample Name']\n",
    "            status = row['status']\n",
    "            sex = row['sex']\n",
    "            age = int(row['AGE'])\n",
    "            sample_name = f\"{status}_{sex}_{age}\"\n",
    "            \n",
    "            # Handle duplicates by adding suffix\n",
    "            base_name = sample_name\n",
    "            counter = 1\n",
    "            while sample_name in sample_mapping.values():\n",
    "                sample_name = f\"{base_name}_{counter}\"\n",
    "                counter += 1\n",
    "            \n",
    "            sample_mapping[gsm] = sample_name\n",
    "    \n",
    "    elif naming_scheme == 'sequential':\n",
    "        # Sort by status and then by AHI (severity)\n",
    "        samples_sorted = samples_df.sort_values(['status', 'ahi'], ascending=[True, False])\n",
    "        \n",
    "        # Count samples per status\n",
    "        status_counts = {}\n",
    "        \n",
    "        for _, row in samples_sorted.iterrows():\n",
    "            gsm = row['Sample Name']\n",
    "            status = row['status']\n",
    "            \n",
    "            if status not in status_counts:\n",
    "                status_counts[status] = 0\n",
    "            status_counts[status] += 1\n",
    "            \n",
    "            sample_name = f\"{status}_{status_counts[status]:03d}\"\n",
    "            sample_mapping[gsm] = sample_name\n",
    "    \n",
    "    return sample_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84674221",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_samplesheet(metadata_file, fastq_base_dir, output_file, naming_scheme='sequential'):\n",
    "    \"\"\"\n",
    "    Generate samplesheet grouping runs by GSM ID\n",
    "    \n",
    "    Args:\n",
    "        metadata_file: Path to SRA metadata TSV file\n",
    "        fastq_base_dir: Base directory where FASTQ files are stored\n",
    "        output_file: Output samplesheet CSV file\n",
    "        naming_scheme: How to name samples ('gsm', 'status', or 'sequential')\n",
    "    \"\"\"\n",
    "    \n",
    "    # Read metadata\n",
    "    df = pd.read_csv(metadata_file)\n",
    "    \n",
    "    def safe_agg(x, field_name):\n",
    "        \"\"\"Aggregate by taking first value, but validate all are the same\"\"\"\n",
    "        unique_vals = x.unique()\n",
    "        if len(unique_vals) > 1:\n",
    "            print(f\"WARNING: Inconsistent {field_name} values found: {unique_vals}\")\n",
    "            print(f\"         Using first value: {unique_vals[0]}\")\n",
    "        return unique_vals[0]\n",
    "    \n",
    "    # Group by Sample Name (GSM ID) to get unique biological samples\n",
    "    samples = df.groupby('Sample Name').agg({\n",
    "        'Run': lambda x: list(x),  # List of all SRR runs\n",
    "        'sex': lambda x: safe_agg(x, 'sex'),\n",
    "        'AGE': lambda x: safe_agg(x, 'AGE'),\n",
    "        'BMI': lambda x: safe_agg(x, 'BMI'),\n",
    "        'ahi': lambda x: safe_agg(x, 'ahi'),\n",
    "        'status': lambda x: safe_agg(x, 'status')\n",
    "    }).reset_index()\n",
    "    \n",
    "    # Generate sample names based on scheme\n",
    "    sample_mapping = generate_sample_names(samples, naming_scheme)\n",
    "    \n",
    "    # Create samplesheet\n",
    "    samplesheet_data = []\n",
    "    \n",
    "    for _, row in samples.iterrows():\n",
    "        gsm_id = row['Sample Name']\n",
    "        sample_id = sample_mapping[gsm_id]\n",
    "        runs = row['Run']\n",
    "        \n",
    "        # Path to directory containing all FASTQ files for this sample\n",
    "        fastq_dir = f\"{fastq_base_dir}/{sample_id}\"\n",
    "        \n",
    "        samplesheet_data.append({\n",
    "            'sample_id': sample_id,\n",
    "            'gsm_id': gsm_id,\n",
    "            'fastq_dir': fastq_dir,\n",
    "            'n_runs': len(runs),\n",
    "            'runs': ','.join(runs),\n",
    "            'sex': row['sex'],\n",
    "            'age': row['AGE'],\n",
    "            'bmi': row['BMI'],\n",
    "            'ahi': row['ahi'],\n",
    "            'status': row['status']\n",
    "        })\n",
    "    \n",
    "    # Create DataFrame and save\n",
    "    samplesheet_df = pd.DataFrame(samplesheet_data)\n",
    "    \n",
    "    # Save full version with metadata\n",
    "    samplesheet_df.to_csv(output_file.replace('.csv', '_full.csv'), index=False)\n",
    "    print(f\"Full samplesheet saved to: {output_file.replace('.csv', '_full.csv')}\")\n",
    "    \n",
    "    # Save minimal version for pipeline\n",
    "    minimal_df = samplesheet_df[['sample_id', 'fastq_dir']]\n",
    "    minimal_df.to_csv(output_file, index=False)\n",
    "    print(f\"Minimal samplesheet saved to: {output_file}\")\n",
    "    \n",
    "    # Print summary\n",
    "    print(f\"\\nSummary:\")\n",
    "    print(f\"Total biological samples: {len(samplesheet_df)}\")\n",
    "    print(f\"Total sequencing runs: {samplesheet_df['n_runs'].sum()}\")\n",
    "    print(f\"\\nRuns per sample:\")\n",
    "    print(samplesheet_df['n_runs'].value_counts().sort_index())\n",
    "    \n",
    "    print(f\"\\nSample breakdown by status:\")\n",
    "    print(samplesheet_df['status'].value_counts())\n",
    "    \n",
    "    return samplesheet_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de53e00c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full samplesheet saved to: metadata/samples_full.csv\n",
      "Minimal samplesheet saved to: metadata/samples.csv\n",
      "\n",
      "Summary:\n",
      "Total biological samples: 22\n",
      "Total sequencing runs: 88\n",
      "\n",
      "Runs per sample:\n",
      "n_runs\n",
      "4    22\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample breakdown by status:\n",
      "status\n",
      "NoOSA    11\n",
      "OSA      11\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = generate_samplesheet('metadata/OSA_SraRunTable.csv','fastq','metadata/samples.csv','sequential')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf641516",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_download_script(metadata_file, output_script, naming_scheme='status'):\n",
    "    \"\"\"\n",
    "    Create a bash script to download FASTQ files organized by sample\n",
    "    \n",
    "    Args:\n",
    "        naming_scheme: How to name samples\n",
    "            - 'gsm': Use GSM IDs (e.g., GSM6617010)\n",
    "            - 'status': Use status_sex_age (e.g., OSA_female_4)\n",
    "            - 'sequential': Use status with numbers (e.g., OSA_001, NoOSA_001)\n",
    "    \"\"\"\n",
    "    \n",
    "    df = pd.read_csv(metadata_file)\n",
    "    \n",
    "    # Group by Sample Name\n",
    "    sample_groups = df.groupby('Sample Name').agg({\n",
    "        'Run': lambda x: list(x),\n",
    "        'sex': lambda x: x.iloc[0],\n",
    "        'AGE': lambda x: x.iloc[0],\n",
    "        'status': lambda x: x.iloc[0]\n",
    "    }).reset_index()\n",
    "    \n",
    "    # Generate sample names based on scheme\n",
    "    sample_mapping = {}\n",
    "    \n",
    "    if naming_scheme == 'gsm':\n",
    "        for _, row in sample_groups.iterrows():\n",
    "            sample_mapping[row['Sample Name']] = row['Sample Name']\n",
    "    \n",
    "    elif naming_scheme == 'status':\n",
    "        for _, row in sample_groups.iterrows():\n",
    "            gsm = row['Sample Name']\n",
    "            status = row['status']\n",
    "            sex = row['sex']\n",
    "            age = int(row['AGE'])\n",
    "            sample_name = f\"{status}_{sex}_{age}\"\n",
    "            \n",
    "            # Handle duplicates by adding suffix\n",
    "            base_name = sample_name\n",
    "            counter = 1\n",
    "            while sample_name in sample_mapping.values():\n",
    "                sample_name = f\"{base_name}_{counter}\"\n",
    "                counter += 1\n",
    "            \n",
    "            sample_mapping[gsm] = sample_name\n",
    "    \n",
    "    elif naming_scheme == 'sequential':\n",
    "        # Count samples per status\n",
    "        status_counts = {'OSA': 0, 'NoOSA': 0}\n",
    "        \n",
    "        for _, row in sample_groups.iterrows():\n",
    "            gsm = row['Sample Name']\n",
    "            status = row['status']\n",
    "            status_counts[status] += 1\n",
    "            sample_name = f\"{status}_{status_counts[status]:03d}\"\n",
    "            sample_mapping[gsm] = sample_name\n",
    "    \n",
    "    with open(output_script, 'w') as f:\n",
    "        f.write(\"#!/bin/bash\\n\\n\")\n",
    "        f.write(\"# Download and organize FASTQ files by sample\\n\")\n",
    "        f.write(\"# Files are renamed to Cell Ranger format\\n\")\n",
    "        f.write(f\"# Naming scheme: {naming_scheme}\\n\")\n",
    "        f.write(\"# Uses SRA Toolkit (prefetch + fasterq-dump)\\n\\n\")\n",
    "        f.write(\"set -e\\n\\n\")\n",
    "        f.write(\"# Check if required tools are installed\\n\")\n",
    "        f.write(\"command -v prefetch >/dev/null 2>&1 || { echo 'prefetch not found. Install SRA Toolkit.'; exit 1; }\\n\")\n",
    "        f.write(\"command -v fasterq-dump >/dev/null 2>&1 || { echo 'fasterq-dump not found. Install SRA Toolkit.'; exit 1; }\\n\")\n",
    "        f.write(\"command -v gzip >/dev/null 2>&1 || { echo 'pigz not found. Install pigz for compression.'; exit 1; }\\n\\n\")\n",
    "        \n",
    "        # Write mapping table as comment\n",
    "        f.write(\"# Sample Mapping:\\n\")\n",
    "        for gsm, sample_name in sample_mapping.items():\n",
    "            f.write(f\"# {gsm} -> {sample_name}\\n\")\n",
    "        f.write(\"\\n\")\n",
    "        \n",
    "        for _, row in sample_groups.iterrows():\n",
    "            gsm = row['Sample Name']\n",
    "            sample_name = sample_mapping[gsm]\n",
    "            runs = row['Run']\n",
    "            \n",
    "            f.write(f\"\\n# {'='*60}\\n\")\n",
    "            f.write(f\"# Sample: {sample_name} (Original: {gsm})\\n\")\n",
    "            f.write(f\"# Status: {row['status']}, Sex: {row['sex']}, Age: {row['AGE']}\\n\")\n",
    "            f.write(f\"# {'='*60}\\n\\n\")\n",
    "            \n",
    "            f.write(f\"echo 'Processing {sample_name}...'\\n\")\n",
    "            f.write(f\"mkdir -p fastq/{sample_name}\\n\")\n",
    "            f.write(f\"cd fastq/{sample_name}\\n\\n\")\n",
    "            \n",
    "            for i, run in enumerate(runs, 1):\n",
    "                f.write(f\"# Lane {i}/4: {run}\\n\")\n",
    "                f.write(f\"echo '  Downloading {run} (Lane {i})...'\\n\")\n",
    "                f.write(f\"prefetch {run} || {{ echo 'Failed to prefetch {run}'; exit 1; }}\\n\")\n",
    "                f.write(f\"fasterq-dump {run} --split-files --include-technical --threads 8 || {{ echo 'Failed to dump {run}'; exit 1; }}\\n\\n\")\n",
    "                \n",
    "                f.write(f\"# For 10x data: _3 = R1 (28bp barcode+UMI), _4 = R2 (90bp cDNA)\\n\")\n",
    "                f.write(f\"# Rename to Cell Ranger format and discard index reads (_1, _2)\\n\")\n",
    "                f.write(f\"if [ -f {run}_3.fastq ] && [ -f {run}_4.fastq ]; then\\n\")\n",
    "                f.write(f\"    echo '  Using _3 as R1 and _4 as R2 (10x Genomics format)'\\n\")\n",
    "                f.write(f\"    mv {run}_3.fastq {sample_name}_S1_L00{i}_R1_001.fastq\\n\")\n",
    "                f.write(f\"    mv {run}_4.fastq {sample_name}_S1_L00{i}_R2_001.fastq\\n\")\n",
    "                f.write(f\"    rm -f {run}_1.fastq {run}_2.fastq  # Remove index reads\\n\")\n",
    "                f.write(f\"elif [ -f {run}_1.fastq ] && [ -f {run}_2.fastq ]; then\\n\")\n",
    "                f.write(f\"    echo '  Using _1 as R1 and _2 as R2 (standard paired-end)'\\n\")\n",
    "                f.write(f\"    mv {run}_1.fastq {sample_name}_S1_L00{i}_R1_001.fastq\\n\")\n",
    "                f.write(f\"    mv {run}_2.fastq {sample_name}_S1_L00{i}_R2_001.fastq\\n\")\n",
    "                f.write(f\"else\\n\")\n",
    "                f.write(f\"    echo 'ERROR: Cannot find expected FASTQ files for {run}'\\n\")\n",
    "                f.write(f\"    ls -lh {run}*.fastq\\n\")\n",
    "                f.write(f\"    exit 1\\n\")\n",
    "                f.write(f\"fi\\n\\n\")\n",
    "                \n",
    "                f.write(f\"# Compress FASTQ files\\n\")\n",
    "                f.write(f\"echo '  Compressing...'\\n\")\n",
    "                f.write(f\"gzip {sample_name}_S1_L00{i}_R1_001.fastq\\n\")\n",
    "                f.write(f\"gzip {sample_name}_S1_L00{i}_R2_001.fastq\\n\\n\")\n",
    "                \n",
    "                f.write(f\"# Clean up SRA file\\n\")\n",
    "                f.write(f\"rm -rf {run}\\n\\n\")\n",
    "            \n",
    "            f.write(f\"cd ../..\\n\")\n",
    "            f.write(f\"echo 'âœ“ Completed {sample_name}'\\n\")\n",
    "            f.write(f\"echo ''\\n\\n\")\n",
    "        \n",
    "        f.write(\"\\necho 'All samples downloaded and renamed!'\\n\")\n",
    "        f.write(\"echo 'Directory structure:'\\n\")\n",
    "        f.write(\"tree fastq/ -L 2\\n\")\n",
    "    \n",
    "    # Save sample mapping to CSV\n",
    "    mapping_df = pd.DataFrame([\n",
    "        {'gsm_id': gsm, 'sample_name': name, **sample_groups[sample_groups['Sample Name'] == gsm].iloc[0].to_dict()}\n",
    "        for gsm, name in sample_mapping.items()\n",
    "    ])\n",
    "    mapping_df = mapping_df[['gsm_id', 'sample_name', 'status', 'sex', 'AGE']]\n",
    "    mapping_file = output_script.replace('.sh', '_mapping.csv')\n",
    "    mapping_df.to_csv(mapping_file, index=False)\n",
    "    \n",
    "    print(f\"Download script saved to: {output_script}\")\n",
    "    print(f\"Sample mapping saved to: {mapping_file}\")\n",
    "    print(f\"Make executable with: chmod +x {output_script}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5fc6efe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download script saved to: metadata/download.sh\n",
      "Sample mapping saved to: metadata/download_mapping.csv\n",
      "Make executable with: chmod +x metadata/download.sh\n"
     ]
    }
   ],
   "source": [
    "create_download_script('metadata/OSA_SraRunTable.csv', 'metadata/download.sh', 'sequential')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gnn_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
